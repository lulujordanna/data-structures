// //Dependencies
var async = require('async');
var AWS = require('aws-sdk');
AWS.config = new AWS.Config();
AWS.config.region = "us-east-1";

//Blog entries creation
var blogEntries = [];

class BlogEntry {
  constructor(category, date, title, entry, url, photo) {
    this.category = {};
    this.category.S = category; 
    
    this.date = {}; 
    this.date.S = new Date(date).toDateString();
    
    this.title = {};
    this.title.S = title;
    
    this.entry = {};
    this.entry.S = entry;
    
    this.url = {};
    this.url.S = url;
    
     if (photo != null) {
      this.photo = {};
      this.photo.S = photo;
    }
    
    this.month = {};
    this.month.N = new Date(date).getMonth().toString();
    
  }
}

blogEntries.push(new BlogEntry('AA Meetings', 'August 30, 2019', 'Week 01: An Introduction to Node JS', 'The goal of the Week 01 Assignment was to use Node.js to make a request for each of the ten "Meeting List Agenda" pages for Alcoholics Anonymous in Manhattan. The final outcome will programmatically convert the HTML pages to text files. Using the starter code as my base, I needed to create two arrays to hold the information for the URLs and text file paths. However, the for() loop was executing faster than the methods inside the loop. By changing the var to a let statement, this created a fresh binding to our iterator versus var which does a single binding for the whole loop. The outcome was successful, however moving forward I would like to learn how to generate the URLs and file names dynamically.', 'https://github.com/lulujordanna/data-structures/tree/master/week01'));
blogEntries.push(new BlogEntry('AA Meetings', 'September 9, 2019', 'Week 02: Parsing and Scraping a Text File', 'Building off of the week 01 assignment, the goal of this project was to use Node.js to read a single text file and create a new file with addresses of the Alcohol Anonymous meetings. I used Zone 10 from the AA map which is file m10. Using npm cheerio, I began to search for the parameters of the table that I needed. Unfortunately, due to the inconsistencies in the HTML formatting I could not just extract the paragraphs themselves. I started by removing the extra divs, spans, and bolded text elements that were not related to the address. I then created a variable called address to get closer to the correct text itself and to strip out any white space. The split() command created an array of these addresses. Using a variable called location, which I had created at the beginning of the assignment, I created a string using the second position in the array (address number and street name) and added "Manhattan NY" to complete the address. Using appendFileSync the information is added to the text file without overwriting the previous information. After further explanation of solutions in class, I have adapted my code to use cheerio to search for the specific styling and parses the elements into an object. It also saves the file as a JSON which is more applicable then a text file for future use.', 'https://github.com/lulujordanna/data-structures/tree/master/week02'));
blogEntries.push(new BlogEntry('AA Meetings', 'September 16, 2019', 'Week 03: An Introduction to Geocoding', 'Using the parsed data from last week, the goal of this assignment was to use the Texas A&M Geoservices Geocoding API to make a request for the geo-locations of all the meetings in the zone. The first step was loading in the content from Week02 to use the object values for the constructed API request. Within the asyncEachSeries, I created three variables to make it faster to reference the values within the JSON. After the URL has been constructed, I created variables to inside the else statement to hold the latitude and longitude information. I then created a variable called fullAddress to store the information for the street address, city, state, latitude and longitude. Using meetingsData.push(fullAddress), this information was pushed to the array. I then wrote a new JSON file with the updated parameters. Moving forward my goal would be to strip out any inconsistencies within the street address and remove any duplicate locations within the JSON file.', 'https://github.com/lulujordanna/data-structures/tree/master/week03'));
blogEntries.push(new BlogEntry('AA Meetings', 'September 23, 2019', 'Week 04: An Introduction to SQL', 'Taking the data that I have parsed from the AA zone, the goal of this week’s assignment is to create a relational database. There are four steps to achieving this goal; planning, creating a table, populating the table and checking the result. When initially planning my database, I thought of the hierarchy of the data itself. While this is beneficial to understanding the structure of content, the structure for a relational database is better suited in multiple tables. Using Illustrator, I mapped out the three tables I will need for the AA data structure; locationGeo, schedule and meetings. Each table has the value name and parameter it needs. Using IDs for the location and meetings, this feeds into the schedule table without having duplicate information. After setting up my database in AWS, I connected the database credentials to my JS file. Using the process.env command I kept my user credentials, host URL and password in my environment variable to ensure these do not end up on GitHub. Once that was completed, I created my locationGeo table in the database. Before I could populate the table, I wanted to ensure that duplicate addresses were removed from the JSON that I was working with. In order to do this, I created two new arrays; addressesForDb and addressesCheck. The addressesForDb will be the final array I use to populate my table, while the check array checks the latitude and longitude for duplicates. Inside the for() loop, I created a variable to first combine the latitude and longitude. Then the if statement checks the latLonCombined is false. The data I wanted was then pushed to the addressesForDb array and the final number of locations for this zone is 13. I then was able to populate the table with the information from the JSON file. However not all of my variables were included in the JSON file at the moment (locationID and addressName) so I used "dummy data" for now which is evident in the INSERT INTO statement of the code. Using the starter code, I was able to check to see that the database had populated correctly. As I do not have the data for the locationId and Address name the result returned a 0 and undefined. While this was successful for adding a single table, I struggled with adding multiple tables. My next step would be to adjust the code to add the additional tables and parse the new data for the locationGeo table and the future tables.', 'https://github.com/lulujordanna/data-structures/tree/master/week04', 'https://github.com/lulujordanna/data-structures/blob/master/week04/files/aaSchema.png'));
blogEntries.push(new BlogEntry('Process Blog', 'October 1, 2019', 'Week 05: An Introduction to NoSQL', 'The goal of this week’s assignment is to begin planning out how to build a NoSQL database and populating that database for our final assignment 2, The Process Blog. I plan on using my documentation from GitHub to showcase my development with JavaScript and my working process of the three final assignments. While the core functionality of each post won’t change (category, date, title, entry), I want there to be flexibility to include other multi-media and link out to webpages. I am using a semi-structured key-value and document database (DynamoDB). For each entry, I am thinking of the following hierarchical structure (see image below) and that the data coming out of the database will look fairly similar. After creating this plan, I modified the BlogEntry object to fit these parameters. I then populated the object and used the .push() method for the data to be stored in the blogEnteries array. Once the array was populated, I wrapped the starter code in a async.EachSeries to loop through the entries and push them to the database. After reflecting on this work, I felt that my NoSQL database was a good start, but there was an issue with inputting images. I originally put a "none" string in that portion of the object as I had no photos to upload yet. After class I was able to switch my code to reflect if a field does not have an item to upload.', 'https://github.com/lulujordanna/data-structures/tree/master/week05', 'https://github.com/lulujordanna/data-structures/blob/master/week05/files/dataStructureProcess.png'));
blogEntries.push(new BlogEntry('AA Meetings', 'October 14, 2019', 'Week 06: SQL Query', 'The goal of the query is to filter meetings based on parameters for the planned map. I queried the address, latitude and longitude as this was the current information, I have populated in the PostgreSQL database.', 'https://github.com/lulujordanna/data-structures/tree/master/week06', 'https://github.com/lulujordanna/data-structures/blob/master/week06/files/SQLQuery.png'));
blogEntries.push(new BlogEntry('AA Meetings', 'October 15, 2019', 'Week 06: SQL Query', 'I found this assignment challenging as I did not have much data to work with. I am currently working on parsing out more information from the HTML pages to be able to create further, more complex queries based on meeting times, day, etc. Below is an image of the final outcome.', 'https://github.com/lulujordanna/data-structures/tree/master/week06', 'https://github.com/lulujordanna/data-structures/blob/master/week06/files/SQLQuery.png'));
blogEntries.push(new BlogEntry('Process Blog', 'October 15, 2019', 'Week 06: NoSQL Query', 'By modifying the starter code I was able to create a successful query from my DynamoDB database. In order to ensure that both the partition key and sort key were expressed in the query, I made the ExpressionAttributeNames align with the two values; category and date. In the final query I requested the Process Blog data between August 30th and December 11th. While there is only one Process Blog entry to be returned (see image below). I did test this out with the AA Meetings entries and changed the date parameters to ensure that different queries were successful.', 'https://github.com/lulujordanna/data-structures/tree/master/week06', 'https://github.com/lulujordanna/data-structures/blob/master/week06/files/NoSQLQuery.png'));
blogEntries.push(new BlogEntry('AA Meetings', 'October 26, 2019', 'Week 07: Restructuring the AA Data', 'The goal of this assignment was to finishing parsing the rest of the data from the assigned zone and update/replace your PostgreSQL table(s) with the new data. Once this was completed, I had to repeat the process for the remaining 9 zones. The completed data should include all the data I want to include for the map in Final Assignment 1. Since, Week 04 the data structure has changed. Based on the information I want and was able to parse, I am moving forward with a two table SQL database. The first table, locationGeo is similar to the structure from before, with a slight changed to the datatype for locationID. While the second table, schedule has changed a lot based on the data parsed and what datatypes they were available. The following image highlights this new structure.', 'https://github.com/lulujordanna/data-structures/tree/master/week07', 'https://github.com/lulujordanna/data-structures/blob/master/week07/images/DS_AA.png'));
blogEntries.push(new BlogEntry('AA Meetings', 'October 27, 2019', 'Week 07: Parsing the Location Data', 'Building upon the structure that we have worked with in the previous weeks, I wanted to add the address name to database. In order to do this I had to add an additional field to parse the addressName key. Once that data was scrapped I created a JSON file (locationGeo10.JSON). I then created a new JS file to tackle the Geo-coding with the JSON file that I parsed. Once the script was complete and the latitude and longitude were parsed from the TAMU API request, I saved this as a new JSON file to show my progression (locationGeo10_Update.JSON). Using the logic and data structure from week04, I began by removing duplicate locations. I then added an additional parameter by using a for() loop to assign a locationID to each address. This was a way to ensure that duplicate addresses were only inputting once in the database and ultimately to connect my locationGeo table to the Schedule table. I then queried the database to ensure that the addresses were correctly inserted. I repeated this process for all remaining zones to complete my locationGeo table. Below is an image of the final query.', 'https://github.com/lulujordanna/data-structures/tree/master/week07', 'https://github.com/lulujordanna/data-structures/blob/master/week07/images/locationsQuery.png'));
blogEntries.push(new BlogEntry('AA Meetings', 'October 28, 2019', 'Week 07: Parsing the Schedule Data', 'Once the locationGeo table was complete I began to parse my data for the schedule table. I needed to figure out a way to connect the unique location IDs with the individual rows of the html page. By bringing in the AWS instance to the JS file, I was able to connect to my database. Using cheerio I parsed through the html to find the street address string in order to compare with the database and then moved onto the meeting details (day, time, meeting type). Var meetingDetails was a variable which I used to clean up the data inside this row. I then created an object This Meeting, to connect the address variable to the unique locationIDs in the database. I then made another object called thisMeetingDetails to clean up the data for the day, time, meeting type and special interest. Both objects were pushed into the meetingData array which was used my fs.writeFileSync command for the JSON file. The structure of this data created a nesting object within the JSON file. I then had to input this into the schedule table of the database.  Initially I had issues inputting my data into the schedule table, however using a nested async function, I helped to ensure that the nesting JSON structure be able to be inserted into the database. I also added an if statement to account for the Special Interest value. As not all meetings have special interest, this accounts for it and inserts a NULL in the database if it was undefined. ', 'https://github.com/lulujordanna/data-structures/tree/master/week07', 'https://github.com/lulujordanna/data-structures/blob/master/week07/images/scheduleQuery.png'));

//blogEntries.push(new BlogEntry('category', 'date', 'title', 'entry', 'https://github.com/lulujordanna/data-structures/tree/master/week', 'photo'));

//console.log(blogEntries);

//Adding blog entries to the DynamoDB
var dynamodb = new AWS.DynamoDB();

async.eachSeries(blogEntries, function(value, callback) {
  var params = {};
  params.Item = value; 
  params.TableName = "processblog";
  
  dynamodb.putItem(params, function (err, data) {
    if (err) console.log(err, err.stack); // an error occurred
    else console.log(data); // successful response
  });
  setTimeout(callback, 1000); 
});